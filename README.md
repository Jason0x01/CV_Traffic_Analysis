智慧交通影像分析與風險評估系統 (Intelligent Traffic Analysis & Risk Assessment System)
專案目標 (Project Objective)
本專案旨在驗證利用單一攝影機影像，透過電腦視覺與AI演算法，對複雜都市交通場景進行深度分析的可行性。目標不僅是偵測與追蹤用路人，更是要主動預測並量化潛在的碰撞風險，將非結構化的影像數據，轉化為可供決-策的結構化洞察。

核心技術棧 (Core Technologies)
程式語言: Python

電腦視覺: OpenCV

AI模型: YOLOv8 (物件偵測與追蹤)

數據分析: Pandas, NumPy

Web應用與視覺化: Streamlit, Matplotlib

挑戰與解決方案 (Key Challenges & Solutions)
挑戰一：如何適應台灣獨特的混合車流環境。
情境：專案初期採用YOLOv8n (Nano)模型，雖速度快，但在處理夜間、多物件遮蔽的影片時，對台灣交通中佔比極高的機車等小型目標，漏檢率偏高。

解決方案：經過分析與權衡，策略性地將模型升級為YOLOv8m (Medium)。此舉成功將模型的mAP指標從37.3提升至50.2，顯著改善了在困難場景下的偵測準確率，為後續分析提供了更貼近台灣真實路況的數據基礎。

挑戰二：如何建立具備學術理論支持的精準碰撞預測模型。
情境：專案初期採用了簡易的「距離趨近」演算法，將物件簡化為無體積的「質點」，導致了大量的假警報。

解決方案：自主設計並迭代了三代演算法，最終進化到在自駕車領域具備堅實理論支持的「未來邊界框交集(IoU)預測模型」。為進一步提升模型的精準度與效率，在進行IoU碰撞模擬前，額外導入了一套兩階段「預篩選 (Pre-filtering)」機制：

速度平滑化 (Velocity Smoothing)：採用移動平均法，過濾因偵測抖動造成的瞬時速度偏差。

行駛方向過濾 (Directional Filtering)：透過計算速度向量的**「點積」**，快速排除非對向行駛的低風險組合，大幅提升運行效率。

挑戰三：如何從龐雜的原始預測訊號中，提煉出有意義的風險事件。
情境：IoU預測演算法雖然精準，但由於其高度敏感性，在22秒影片中仍產生了數千次的原始碰撞訊號。

解決方案：設計並實作了一套「兩階段數據精煉 (Two-Stage Data Refining)」的後處理流程（事件彙總與持續時間過濾），成功將數千筆原始訊號，最終提煉為 178 次更具真實風險意義的核心事件，完成了從「雜訊」到「情報」的關鍵一步。

最終應用與成果 (Final Application & Outcome)
成功將所有分析流程，整合成一個以 Streamlit 打造的互動式「智慧交通戰情室」儀表板。使用者不僅能看到宏觀的數據洞察（如風險類別分佈、TTC緊急程度分佈），更能以互動方式，從精煉後的事件中，選擇任一事件進行視覺化回放，清晰地了解風險發生的瞬間與相關物件。

未來展望與優化方向 (Future Outlook & Optimization Paths)
本專案成功驗證了核心技術的可行性。考量到個人專案在硬體感測器（單一攝影機）、數據標註資源、與運算能力上的限制，未來若有更充足的資源，可朝以下方向持續深化：

導入場景理解 (Scene Understanding)：引入語意分割模型辨識車道線、人行道，並建立佔用網格地圖解決物件遮蔽問題。

模型微調 (Model Fine-Tuning)：蒐集並標註在地交通影像數據集，對YOLOv8模型進行微調，以提升對各型機車的辨識率。

更先進的軌跡預測 (Advanced Trajectory Prediction)：引入卡爾曼濾波或RNN等模型，預測更複雜的非線性運動。